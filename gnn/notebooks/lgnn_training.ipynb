{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Supervised Community Detection with Hierarchical Graph Neural Networks\n",
    "https://arxiv.org/abs/1705.08415\n",
    "\n",
    "Author's implementation: https://github.com/joanbruna/GNN_community\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dgl.data import SBMMixture\n",
    "import gnn\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--batch-size', type=int, help='Batch size', default=1)\n",
    "# parser.add_argument('--gpu', type=int, help='GPU index', default=-1)\n",
    "# parser.add_argument('--lr', type=float, help='Learning rate', default=0.001)\n",
    "# parser.add_argument('--n-communities', type=int, help='Number of communities', default=2)\n",
    "# parser.add_argument('--n-epochs', type=int, help='Number of epochs', default=100)\n",
    "# parser.add_argument('--n-features', type=int, help='Number of features', default=16)\n",
    "# parser.add_argument('--n-graphs', type=int, help='Number of graphs', default=10)\n",
    "# parser.add_argument('--n-layers', type=int, help='Number of layers', default=30)\n",
    "# parser.add_argument('--n-nodes', type=int, help='Number of nodes', default=10000)\n",
    "# parser.add_argument('--optim', type=str, help='Optimizer', default='Adam')\n",
    "# parser.add_argument('--radius', type=int, help='Radius', default=3)\n",
    "# parser.add_argument('--verbose', action='store_true')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev = th.device('cpu') if args.gpu < 0 else th.device('cuda:%d' % args.gpu)\n",
    "K = 23 #args.n_communities\n",
    "\n",
    "training_dataset = SBMMixture(n_graphs=20, n_nodes=3500, K)\n",
    "training_loader = DataLoader(training_dataset, args.batch_size,\n",
    "                             collate_fn=training_dataset.collate_fn, drop_last=True)\n",
    "\n",
    "ones = th.ones(args.n_nodes // K)\n",
    "y_list = [th.cat([x * ones for x in p]).long().to(dev) for p in permutations(range(K))]\n",
    "\n",
    "feats = [1] + [args.n_features] * args.n_layers + [K]\n",
    "model = gnn.GNN(feats, args.radius, K).to(dev)\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=args.lr)\n",
    "\n",
    "def compute_overlap(z_list):\n",
    "    ybar_list = [th.max(z, 1)[1] for z in z_list]\n",
    "    overlap_list = []\n",
    "    for y_bar in ybar_list:\n",
    "        accuracy = max(th.sum(y_bar == y).item() for y in y_list) / args.n_nodes\n",
    "        overlap = (accuracy - 1 / K) / (1 - 1 / K)\n",
    "        overlap_list.append(overlap)\n",
    "    return sum(overlap_list) / len(overlap_list)\n",
    "\n",
    "def from_np(f, *args):\n",
    "    def wrap(*args):\n",
    "        new = [th.from_numpy(x) if isinstance(x, np.ndarray) else x for x in args]\n",
    "        return f(*new)\n",
    "    return wrap\n",
    "\n",
    "@from_np\n",
    "def step(i, j, g, lg, deg_g, deg_lg, pm_pd):\n",
    "    \"\"\" One step of training. \"\"\"\n",
    "    deg_g = deg_g.to(dev)\n",
    "    deg_lg = deg_lg.to(dev)\n",
    "    pm_pd = pm_pd.to(dev)\n",
    "    t0 = time.time()\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd)\n",
    "    t_forward = time.time() - t0\n",
    "\n",
    "    z_list = th.chunk(z, args.batch_size, 0)\n",
    "    loss = sum(min(F.cross_entropy(z, y) for y in y_list) for z in z_list) / args.batch_size\n",
    "    overlap = compute_overlap(z_list)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    t0 = time.time()\n",
    "    loss.backward()\n",
    "    t_backward = time.time() - t0\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, overlap, t_forward, t_backward\n",
    "\n",
    "@from_np\n",
    "def inference(g, lg, deg_g, deg_lg, pm_pd):\n",
    "    deg_g = deg_g.to(dev)\n",
    "    deg_lg = deg_lg.to(dev)\n",
    "    pm_pd = pm_pd.to(dev)\n",
    "\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd)\n",
    "\n",
    "    return z\n",
    "def test():\n",
    "    p_list =[6, 5.5, 5, 4.5, 1.5, 1, 0.5, 0]\n",
    "    q_list =[0, 0.5, 1, 1.5, 4.5, 5, 5.5, 6]\n",
    "    N = 1\n",
    "    overlap_list = []\n",
    "    for p, q in zip(p_list, q_list):\n",
    "        dataset = SBMMixture(N, args.n_nodes, K, pq=[[p, q]] * N)\n",
    "        loader = DataLoader(dataset, N, collate_fn=dataset.collate_fn)\n",
    "        g, lg, deg_g, deg_lg, pm_pd = next(iter(loader))\n",
    "        z = inference(g, lg, deg_g, deg_lg, pm_pd)\n",
    "        overlap_list.append(compute_overlap(th.chunk(z, N, 0)))\n",
    "    return overlap_list\n",
    "\n",
    "n_iterations = args.n_graphs // args.batch_size\n",
    "for i in range(args.n_epochs):\n",
    "    total_loss, total_overlap, s_forward, s_backward = 0, 0, 0, 0\n",
    "    for j, [g, lg, deg_g, deg_lg, pm_pd] in enumerate(training_loader):\n",
    "        loss, overlap, t_forward, t_backward = step(i, j, g, lg, deg_g, deg_lg, pm_pd)\n",
    "\n",
    "        total_loss += loss\n",
    "        total_overlap += overlap\n",
    "        s_forward += t_forward\n",
    "        s_backward += t_backward\n",
    "\n",
    "        epoch = '0' * (len(str(args.n_epochs)) - len(str(i)))\n",
    "        iteration = '0' * (len(str(n_iterations)) - len(str(j)))\n",
    "        if args.verbose:\n",
    "            print('[epoch %s%d iteration %s%d]loss %.3f | overlap %.3f'\n",
    "                  % (epoch, i, iteration, j, loss, overlap))\n",
    "\n",
    "    epoch = '0' * (len(str(args.n_epochs)) - len(str(i)))\n",
    "    loss = total_loss / (j + 1)\n",
    "    overlap = total_overlap / (j + 1)\n",
    "    t_forward = s_forward / (j + 1)\n",
    "    t_backward = s_backward / (j + 1)\n",
    "    print('[epoch %s%d]loss %.3f | overlap %.3f | forward time %.3fs | backward time %.3fs'\n",
    "          % (epoch, i, loss, overlap, t_forward, t_backward))\n",
    "\n",
    "    overlap_list = test()\n",
    "    overlap_str = ' - '.join(['%.3f' % overlap for overlap in overlap_list])\n",
    "    print('[epoch %s%d]overlap: %s' % (epoch, i, overlap_str))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}